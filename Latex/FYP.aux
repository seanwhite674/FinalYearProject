\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\bibstyle{plainurl}
\providecommand \oddpage@label [2]{}
\citation{GRbook}
\citation{GRbook}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Gravitational Waves Background}{1}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Plane Wave Solution from General Relativity}{1}{section.1.1}\protected@file@percent }
\newlabel{sec:GRintro}{{1.1}{1}{Plane Wave Solution from General Relativity}{section.1.1}{}}
\citation{intoGRSarp}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.1}Leading-Order Power Emission by Gravitational Waves}{2}{subsection.1.1.1}\protected@file@percent }
\newlabel{subsec:GW_power}{{1.1.1}{2}{Leading-Order Power Emission by Gravitational Waves}{subsection.1.1.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.2}Quasi-circular Inspiral of two Point Masses}{2}{subsection.1.1.2}\protected@file@percent }
\newlabel{subsec:two_mass_example}{{1.1.2}{2}{Quasi-circular Inspiral of two Point Masses}{subsection.1.1.2}{}}
\newlabel{eq:E_dot_2}{{1.9}{2}{Quasi-circular Inspiral of two Point Masses}{equation.1.9}{}}
\newlabel{eq:Energy}{{1.10}{2}{Quasi-circular Inspiral of two Point Masses}{equation.1.10}{}}
\citation{GRbook}
\citation{GRbook}
\citation{mismatch,Ogpaper}
\newlabel{eq:GW_strain}{{1.11}{3}{Quasi-circular Inspiral of two Point Masses}{equation.1.11}{}}
\newlabel{eq:hp_time}{{1.12a}{3}{Quasi-circular Inspiral of two Point Masses}{equation.1.12a}{}}
\newlabel{eq:hc_time}{{1.12b}{3}{Quasi-circular Inspiral of two Point Masses}{equation.1.12b}{}}
\newlabel{eq:char_strain}{{1.12c}{3}{Quasi-circular Inspiral of two Point Masses}{equation.1.12c}{}}
\newlabel{eq:hfreq}{{1.13}{3}{Quasi-circular Inspiral of two Point Masses}{equation.1.13}{}}
\newlabel{eq:hplus_freq}{{1.13a}{3}{Quasi-circular Inspiral of two Point Masses}{equation.1.13a}{}}
\newlabel{eq:hcross_freq}{{1.13b}{3}{Quasi-circular Inspiral of two Point Masses}{equation.1.13b}{}}
\newlabel{eq:A_amp}{{1.14a}{3}{Quasi-circular Inspiral of two Point Masses}{equation.1.14a}{}}
\newlabel{eq:psi_cross}{{1.14b}{3}{Quasi-circular Inspiral of two Point Masses}{equation.1.14b}{}}
\newlabel{eq:psi_plus}{{1.14c}{3}{Quasi-circular Inspiral of two Point Masses}{equation.1.14c}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.3}Introducing the Waveform Mismatch}{3}{subsection.1.1.3}\protected@file@percent }
\newlabel{subsec:mismatch_intro}{{1.1.3}{3}{Introducing the Waveform Mismatch}{subsection.1.1.3}{}}
\newlabel{eq:mismatch_def}{{1.15}{3}{Introducing the Waveform Mismatch}{equation.1.15}{}}
\citation{linearcombination}
\citation{Bayesianapproach}
\citation{Ogpaper}
\citation{Ogpaper}
\citation{NRsimulation}
\citation{bestNRfitS}
\citation{NRfitMP}
\citation{NRfitMT}
\citation{Ogpaper}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}GW Approximation using Bayesian Methods}{4}{section.1.2}\protected@file@percent }
\newlabel{sec:GW_and_Bayes}{{1.2}{4}{GW Approximation using Bayesian Methods}{section.1.2}{}}
\citation{Ogpaper}
\citation{bestNRfitS}
\citation{NRsurrogate}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces Motivating the NR Bayesian Method.}}{5}{figure.caption.5}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:projectmotivation}{{1.1}{5}{Motivating the NR Bayesian Method}{figure.caption.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Project Motivation}{5}{section.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.4}Data Description}{6}{section.1.4}\protected@file@percent }
\newlabel{sec:data_description}{{1.4}{6}{Data Description}{section.1.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces Visualising a binary black hole system and it's intrinsic parameters}}{6}{figure.caption.6}\protected@file@percent }
\newlabel{fig:gr_diagram}{{1.2}{6}{Visualising a binary black hole system and it's intrinsic parameters}{figure.caption.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.3}{\ignorespaces Visualisation of the input data across reduced dimensions.}}{7}{figure.caption.7}\protected@file@percent }
\newlabel{fig:visualising_data}{{1.3}{7}{Visualisation of the input data across reduced dimensions}{figure.caption.7}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Gaussian Process Regression Background}{8}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Introduction and Roadmap}{8}{section.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Gaussian Proces Regression Background}{8}{section.2.2}\protected@file@percent }
\newlabel{sec: GP_backgroound}{{2.2}{8}{Gaussian Proces Regression Background}{section.2.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Definition of a Gaussian Process}{8}{subsection.2.2.1}\protected@file@percent }
\newlabel{sec: Definition_of_GP}{{2.2.1}{8}{Definition of a Gaussian Process}{subsection.2.2.1}{}}
\newlabel{eq: Initial_GP_distribution}{{2.1}{8}{Definition of a Gaussian Process}{equation.2.1}{}}
\citation{bible}
\newlabel{eq: meandef}{{2.2}{9}{Definition of a Gaussian Process}{equation.2.2}{}}
\newlabel{eq: kerneldef}{{2.3}{9}{Definition of a Gaussian Process}{equation.2.3}{}}
\newlabel{eq: Multivariate_distribution}{{2.6}{9}{Definition of a Gaussian Process}{equation.2.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}The Prior Distribution}{9}{subsection.2.2.2}\protected@file@percent }
\newlabel{sec: prior_dist}{{2.2.2}{9}{The Prior Distribution}{subsection.2.2.2}{}}
\newlabel{eq: Multivariate prior}{{2.7}{9}{The Prior Distribution}{equation.2.7}{}}
\citation{bible}
\citation{kernelcookbook}
\citation{bible}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Kernel Functions}{10}{section.2.3}\protected@file@percent }
\newlabel{sec: Kernels}{{2.3}{10}{Kernel Functions}{section.2.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Visualising the assumptions the kernel encodes into our GP process.}}{10}{figure.caption.8}\protected@file@percent }
\newlabel{fig: samples_from_GP_prior}{{2.1}{10}{Visualising the assumptions the kernel encodes into our GP process}{figure.caption.8}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2.1}{\ignorespaces Visual comparison of common kernel functions and their effect on Gaussian process priors. }}{11}{table.caption.9}\protected@file@percent }
\newlabel{tab:kernel-examples}{{2.1}{11}{Visual comparison of common kernel functions and their effect on Gaussian process priors}{table.caption.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Visualising the effect of kernel hyper-parameters.}}{12}{figure.caption.10}\protected@file@percent }
\newlabel{fig: GPprior_hyperparams}{{2.2}{12}{Visualising the effect of kernel hyper-parameters}{figure.caption.10}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Building the Posterior Distribution}{12}{section.2.4}\protected@file@percent }
\newlabel{sec: priortoposterior}{{2.4}{12}{Building the Posterior Distribution}{section.2.4}{}}
\newlabel{eq: predictive_mean}{{2.9b}{12}{Building the Posterior Distribution}{equation.2.9b}{}}
\newlabel{eq: predictive_variance}{{2.9c}{12}{Building the Posterior Distribution}{equation.2.9c}{}}
\newlabel{eq: predictive_dist}{{2.9}{12}{Building the Posterior Distribution}{equation.2.9c}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Building the posterior distribution}}{13}{figure.caption.11}\protected@file@percent }
\newlabel{fig: priortoposterior}{{2.3}{13}{Building the posterior distribution}{figure.caption.11}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.5}Handling Noise in our Data}{13}{section.2.5}\protected@file@percent }
\newlabel{sec: Handlingnoise}{{2.5}{13}{Handling Noise in our Data}{section.2.5}{}}
\newlabel{eq: prior_distribution_noise}{{2.12}{13}{Handling Noise in our Data}{equation.2.12}{}}
\newlabel{eq: predictive_mean_noise}{{2.13b}{14}{Handling Noise in our Data}{equation.2.13b}{}}
\newlabel{eq: predictive_variance_noise}{{2.13c}{14}{Handling Noise in our Data}{equation.2.13c}{}}
\newlabel{eq: predictive_distribution_noise}{{2.13}{14}{Handling Noise in our Data}{equation.2.13c}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.1}Homoscedastic Noise}{14}{subsection.2.5.1}\protected@file@percent }
\newlabel{eq: prior_withnoise}{{2.14}{14}{Homoscedastic Noise}{equation.2.14}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Visualising the effect of noise on samples from the GP prior.}}{14}{figure.caption.12}\protected@file@percent }
\newlabel{fig: kernel_noise}{{2.4}{14}{Visualising the effect of noise on samples from the GP prior}{figure.caption.12}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.2}Heteroscedastic Noise}{15}{subsection.2.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Known Noise:}{15}{section*.13}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Learning Noise over the Input Space:}{15}{section*.14}\protected@file@percent }
\newlabel{eq:additive_kernel}{{2.15}{15}{Learning Noise over the Input Space:}{equation.2.15}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.3}Monte Carlo Sampling of Noise}{15}{subsection.2.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.4}Comparing Noise Models}{15}{subsection.2.5.4}\protected@file@percent }
\citation{bible}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces Comparing samples taken from a GP with Homoscedastic noise,Heterscedastic noise and monte carlo sampling of the noise.}}{16}{figure.caption.15}\protected@file@percent }
\newlabel{fig:noise_comparison}{{2.5}{16}{Comparing samples taken from a GP with Homoscedastic noise,Heterscedastic noise and monte carlo sampling of the noise}{figure.caption.15}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.6}Hyper-parameters}{16}{section.2.6}\protected@file@percent }
\newlabel{sec: Hyper_parameters}{{2.6}{16}{Hyper-parameters}{section.2.6}{}}
\newlabel{eq: 5}{{2.16}{16}{Hyper-parameters}{equation.2.16}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces Visualising the log likelihood optimisation surfaces over the model parameters.}}{17}{figure.caption.16}\protected@file@percent }
\newlabel{fig:Optimising_Hyperparams}{{2.6}{17}{Visualising the log likelihood optimisation surfaces over the model parameters}{figure.caption.16}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.7}Quantifying Hyper-parameter Uncertainty}{17}{section.2.7}\protected@file@percent }
\newlabel{sec: MCMC}{{2.7}{17}{Quantifying Hyper-parameter Uncertainty}{section.2.7}{}}
\citation{bible}
\citation{gprthesis}
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces Visualising the posterior distribution of the hyper-parameters using MCMC.}}{18}{figure.caption.17}\protected@file@percent }
\newlabel{fig:MCMCresults}{{2.7}{18}{Visualising the posterior distribution of the hyper-parameters using MCMC}{figure.caption.17}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.8}Multi-Dimensional GPR}{19}{section.2.8}\protected@file@percent }
\newlabel{sec:multidims}{{2.8}{19}{Multi-Dimensional GPR}{section.2.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.8}{\ignorespaces Visualising the construction of a multi-dimensional kernel.}}{19}{figure.caption.18}\protected@file@percent }
\newlabel{fig:2dkernels}{{2.8}{19}{Visualising the construction of a multi-dimensional kernel}{figure.caption.18}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Methods}{20}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Flow chart of the process taken from data processing to selecting the best performing model.}}{20}{figure.caption.19}\protected@file@percent }
\newlabel{fig:flowchart}{{3.1}{20}{Flow chart of the process taken from data processing to selecting the best performing model}{figure.caption.19}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}The Models}{20}{section.3.1}\protected@file@percent }
\newlabel{subsec:Models}{{3.1}{20}{The Models}{section.3.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}Homoscedastic Noise Models}{20}{subsection.3.1.1}\protected@file@percent }
\citation{metrics}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.2}Heteroscedastic Noise Models}{21}{subsection.3.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.3}Hybrid Model}{21}{subsection.3.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.4}Model Evaluation Metrics}{21}{subsection.3.1.4}\protected@file@percent }
\newlabel{sec:metrics}{{3.1.4}{21}{Model Evaluation Metrics}{subsection.3.1.4}{}}
\citation{metrics}
\citation{bible}
\@writefile{lot}{\contentsline {table}{\numberline {3.1}{\ignorespaces Listing model variations used in cross validation runs.}}{22}{table.caption.20}\protected@file@percent }
\newlabel{tab:model_summary}{{3.1}{22}{Listing model variations used in cross validation runs}{table.caption.20}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.5}AEE Metrics}{22}{subsection.3.1.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.6}Correlation Metrics}{22}{subsection.3.1.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Model Training, Testing and Comparisons}{23}{section.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Cross Validation on all Model Types}{23}{subsection.3.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}Final Testing}{23}{subsection.3.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.3}Implementation Details}{23}{subsection.3.2.3}\protected@file@percent }
\newlabel{subsubsec:implementdetails}{{3.2.3}{23}{Implementation Details}{subsection.3.2.3}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Results}{24}{chapter.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Cross-Validation Performance}{24}{section.4.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Comparing average metrics over all cross validation folds between all model types.}}{24}{figure.caption.21}\protected@file@percent }
\newlabel{fig:broad_comparison}{{4.1}{24}{Comparing average metrics over all cross validation folds between all model types}{figure.caption.21}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Visualising the ranking of each model after cross validation.}}{25}{figure.caption.22}\protected@file@percent }
\newlabel{fig:CV_sidebyside}{{4.2}{25}{Visualising the ranking of each model after cross validation}{figure.caption.22}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Training on 90\% of Data}{25}{section.4.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces Visualising the ranking of each model on the test data.}}{26}{figure.caption.23}\protected@file@percent }
\newlabel{fig:comparing_metrics}{{4.3}{26}{Visualising the ranking of each model on the test data}{figure.caption.23}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces Comparing Cross-cuts of best 8 models.}}{27}{figure.caption.24}\protected@file@percent }
\newlabel{fig:crosscuts_bestmodels}{{4.4}{27}{Comparing Cross-cuts of best 8 models}{figure.caption.24}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces The optimized hyperparameters for the final 8 GPR models.}}{27}{table.caption.25}\protected@file@percent }
\newlabel{tab:final_gpr_hyperparams}{{4.1}{27}{The optimized hyperparameters for the final 8 GPR models}{table.caption.25}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Hyper-parameter Uncertainty}{28}{section.4.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces The hyper-parameter posterior of the best \texttt  {RBFMatern} model.}}{28}{figure.caption.26}\protected@file@percent }
\newlabel{fig:MCMCRBFMatern}{{4.5}{28}{The hyper-parameter posterior of the best \texttt {RBFMatern} model}{figure.caption.26}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces Comparing the pointwise \text  {RBFMatern} model with an alternative marginalised over its hyper-parmeters.}}{29}{figure.caption.27}\protected@file@percent }
\newlabel{fig:MCMCvsmarginalised}{{4.6}{29}{Comparing the pointwise \text {RBFMatern} model with an alternative marginalised over its hyper-parmeters}{figure.caption.27}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.2}{\ignorespaces Comparing metrics between the pointwise \texttt  {RBFMatern} model and its equivalent model marginalised over the hyper-parameters.}}{29}{table.caption.28}\protected@file@percent }
\newlabel{tab:pointwise_vs_mcmc}{{4.2}{29}{Comparing metrics between the pointwise \texttt {RBFMatern} model and its equivalent model marginalised over the hyper-parameters}{table.caption.28}{}}
\citation{kernelposterior}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Conclusion}{30}{chapter.5}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{sec:conclusion}{{5}{30}{Conclusion}{chapter.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Further work:}{30}{section.5.1}\protected@file@percent }
\bibdata{references}
\bibcite{linearcombination}{1}
\bibcite{intoGRSarp}{2}
\bibcite{Bayesianapproach}{3}
\bibcite{NRsimulation}{4}
\bibcite{kernelcookbook}{5}
\bibcite{gprthesis}{6}
\bibcite{NRfitMT}{7}
\bibcite{Ogpaper}{8}
\bibcite{kernelposterior}{9}
\bibcite{GRbook}{10}
\bibcite{mismatch}{11}
\bibcite{NRfitMP}{12}
\bibcite{bestNRfitS}{13}
\bibcite{bible}{14}
\bibcite{NRsurrogate}{15}
\bibcite{metrics}{16}
\@writefile{toc}{\contentsline {section}{\numberline {.1}Derivation of Predictive Distribution}{34}{section.Alph0.1}\protected@file@percent }
\newlabel{appendix:A}{{.1}{34}{Derivation of Predictive Distribution}{section.Alph0.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {.1.1}Kernel Formulas}{34}{subsection.Alph0.1.1}\protected@file@percent }
\newlabel{appendix:B}{{.1.1}{34}{Kernel Formulas}{subsection.Alph0.1.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {.1.2}Graphs of 4d finalist GPs}{36}{subsection.Alph0.1.2}\protected@file@percent }
\newlabel{appendix:C}{{.1.2}{36}{Graphs of 4d finalist GPs}{subsection.Alph0.1.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces \textcolor {orange}{\texttt  {TODO: Improve caption}} All 8 gps with cutting their y-axis}}{36}{figure.caption.36}\protected@file@percent }
\newlabel{fig:best8_ycuts}{{1}{36}{\todo {Improve caption} All 8 gps with cutting their y-axis}{figure.caption.36}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces All 8 gps with cutting their x-axis}}{37}{figure.caption.37}\protected@file@percent }
\newlabel{fig:best8_xcuts}{{2}{37}{All 8 gps with cutting their x-axis}{figure.caption.37}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Examining my chosen model RBF Matern kernel}}{38}{figure.caption.38}\protected@file@percent }
\newlabel{fig:RBF_Matern_xcuts}{{3}{38}{Examining my chosen model RBF Matern kernel}{figure.caption.38}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {.1.3}Model Evaluation Table and graphs}{38}{subsection.Alph0.1.3}\protected@file@percent }
\newlabel{appendix:D}{{.1.3}{38}{Model Evaluation Table and graphs}{subsection.Alph0.1.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Seeing how the best models performed over different clusters}}{38}{figure.caption.39}\protected@file@percent }
\newlabel{fig:boxplots}{{4}{38}{Seeing how the best models performed over different clusters}{figure.caption.39}{}}
\citation{bible}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Final Model Rankings after training on 90\% and testing on 10\%}}{39}{table.caption.40}\protected@file@percent }
\newlabel{tab:finalmadelsrankingtable}{{1}{39}{Final Model Rankings after training on 90\% and testing on 10\%}{table.caption.40}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces All 32 Model Rankings from CV}}{39}{table.caption.41}\protected@file@percent }
\newlabel{tab:rankingtable}{{2}{39}{All 32 Model Rankings from CV}{table.caption.41}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {.1.4}Bin}{39}{subsection.Alph0.1.4}\protected@file@percent }
\newlabel{appendix:bin}{{.1.4}{39}{Bin}{subsection.Alph0.1.4}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Comparison of different performance metrics used in evaluating models. RMSE, \( R^2 \), FOM, and the Pearson Coefficient are included. MAE is similar to RMSE but without squaring errors. Adjusted \( R^2 \) accounts for the number of predictors and is slightly modified from \( R^2 \). The actual metrics for each graph are: RMSE = 0.2, \( R^2 \) = 0.6, FOM = 1.09, Pearson correlation = 0.8.}}{40}{table.caption.42}\protected@file@percent }
\newlabel{tab:metrics-comparison}{{3}{40}{Comparison of different performance metrics used in evaluating models. RMSE, \( R^2 \), FOM, and the Pearson Coefficient are included. MAE is similar to RMSE but without squaring errors. Adjusted \( R^2 \) accounts for the number of predictors and is slightly modified from \( R^2 \). The actual metrics for each graph are: RMSE = 0.2, \( R^2 \) = 0.6, FOM = 1.09, Pearson correlation = 0.8}{table.caption.42}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {.1.5}MCMC details}{41}{subsection.Alph0.1.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Overview of the MCMC sampling procedure for Gaussian Process hyperparameter inference. This pipeline samples from the posterior \( p(\theta \mid \mathbf  {y}, X) \) using a Metropolis-Hastings Gaussian proposal and an ensemble of walkers.}}{41}{figure.caption.44}\protected@file@percent }
\newlabel{fig:MCMC flowchart}{{5}{41}{Overview of the MCMC sampling procedure for Gaussian Process hyperparameter inference. This pipeline samples from the posterior \( p(\theta \mid \mathbf {y}, X) \) using a Metropolis-Hastings Gaussian proposal and an ensemble of walkers}{figure.caption.44}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {.1.6}Noise modeling using Monte Carlo Sampling}{41}{subsection.Alph0.1.6}\protected@file@percent }
\newlabel{appendix:monte_carlo}{{.1.6}{41}{Noise modeling using Monte Carlo Sampling}{subsection.Alph0.1.6}{}}
\gdef \@abspage@last{49}
