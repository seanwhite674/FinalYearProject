{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c1689a17-5e06-4eae-a113-008e4100f28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy.linalg as npl\n",
    "from scipy.optimize import minimize\n",
    "import math as math\n",
    "from itertools import combinations\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n",
    "from sklearn.gaussian_process.kernels import WhiteKernel\n",
    "import matplotlib.lines as mlines\n",
    "from sklearn.model_selection import train_test_split\n",
    "import csv\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from scipy.interpolate import griddata\n",
    "from scipy.spatial import distance_matrix\n",
    "from scipy import interpolate\n",
    "from sklearn.model_selection import KFold\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3676d8a1-8c4b-4714-a847-3fca8e8e9e28",
   "metadata": {},
   "source": [
    "## Here I take 50 points from training data at random from each mass\n",
    "I need to try where I take 200 points from whole data set and not 50 from each "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b5698f94-3e43-47a0-88a1-a66c14d07441",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>w</th>\n",
       "      <th>data</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>-1.439897</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-2.831628</td>\n",
       "      <td>0.561478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>-1.308997</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-3.006489</td>\n",
       "      <td>0.485720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1</td>\n",
       "      <td>-1.178097</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-2.354835</td>\n",
       "      <td>1.270193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.1</td>\n",
       "      <td>-1.047198</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-2.974002</td>\n",
       "      <td>0.983807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.916298</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-2.401510</td>\n",
       "      <td>1.254378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.7</td>\n",
       "      <td>1.570796</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-2.287634</td>\n",
       "      <td>2.337560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.8</td>\n",
       "      <td>1.570796</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-2.164392</td>\n",
       "      <td>1.612457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.9</td>\n",
       "      <td>1.570796</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-2.152368</td>\n",
       "      <td>1.550488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.439897</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-2.579505</td>\n",
       "      <td>0.442328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.439897</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-2.114922</td>\n",
       "      <td>0.416658</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       x         y    z     w      data     error\n",
       "0    0.1 -1.439897  0.0  0.25 -2.831628  0.561478\n",
       "1    0.1 -1.308997  0.5  0.25 -3.006489  0.485720\n",
       "2    0.1 -1.178097  1.0  0.25 -2.354835  1.270193\n",
       "3    0.1 -1.047198  1.0  0.25 -2.974002  0.983807\n",
       "4    0.1 -0.916298  1.0  0.25 -2.401510  1.254378\n",
       "..   ...       ...  ...   ...       ...       ...\n",
       "995  0.7  1.570796 -1.0  1.00 -2.287634  2.337560\n",
       "996  0.8  1.570796 -1.0  1.00 -2.164392  1.612457\n",
       "997  0.9  1.570796 -1.0  1.00 -2.152368  1.550488\n",
       "998  1.0 -1.439897 -1.0  1.00 -2.579505  0.442328\n",
       "999  1.0  1.439897 -1.0  1.00 -2.114922  0.416658\n",
       "\n",
       "[1000 rows x 6 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = [\"x\",\"y\",\"z\",\"w\",\"data\",\"error\"]\n",
    "datatab = pd.read_table(\"Updateddata.txt\",names = columns)\n",
    "datatab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8c8a7359-acb1-4bda-adc2-8501bc468d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = datatab['x']\n",
    "y = datatab['y']\n",
    "z = datatab['z']\n",
    "w = datatab['w']\n",
    "data = datatab['data']\n",
    "error = datatab['error']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e880c3a8-a5f4-44aa-bf72-d8d425fb7094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First dataset \n",
    "datam1 = datatab[0:250]\n",
    "xm1 = datam1['x'].values\n",
    "ym1 = datam1['y'].values\n",
    "zm1 = datam1['z'].values\n",
    "wm1 = datam1['w'].values\n",
    "dm1 = datam1['data'].values\n",
    "em1 = datam1['error'].values\n",
    "X1 = np.column_stack((xm1, ym1, zm1, wm1))\n",
    "\n",
    "# Second dataset\n",
    "datam2 = datatab[250:500]\n",
    "xm2 = datam2['x'].values\n",
    "ym2 = datam2['y'].values\n",
    "zm2 = datam2['z'].values\n",
    "wm2 = datam2['w'].values\n",
    "dm2 = datam2['data'].values\n",
    "em2 = datam2['error'].values\n",
    "X2 = np.column_stack((xm2, ym2, zm2, wm2))\n",
    "\n",
    "# Third dataset\n",
    "datam3 = datatab[500:750]\n",
    "xm3 = datam3['x'].values\n",
    "ym3 = datam3['y'].values\n",
    "zm3 = datam3['z'].values\n",
    "wm3 = datam3['w'].values\n",
    "dm3 = datam3['data'].values\n",
    "em3 = datam3['error'].values\n",
    "X3 = np.column_stack((xm3, ym3, zm3, wm3))\n",
    "\n",
    "# Fourth dataset\n",
    "datam4 = datatab[750:]\n",
    "xm4 = datam4['x'].values\n",
    "ym4 = datam4['y'].values\n",
    "zm4 = datam4['z'].values\n",
    "wm4 = datam4['w'].values\n",
    "dm4 = datam4['data'].values\n",
    "em4 = datam4['error'].values\n",
    "X4 = np.column_stack((xm4, ym4, zm4, wm4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "26e35466-d128-42b6-93b6-1f12b7bae933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000,)\n",
      "(1000,)\n",
      "(1000, 4)\n"
     ]
    }
   ],
   "source": [
    "X = np.column_stack((x,y, z, w))\n",
    "D = np.concatenate((dm1,dm2,dm3,dm4))\n",
    "E = np.concatenate((em1,em2,em3,em4))\n",
    "print(D.shape)\n",
    "print(E.shape)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "cc9e9b4e-7a3a-4573-b524-7e5f37287ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  50%|█████     | 1/2 [00:20<00:20, 20.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1: Fitted Kernel: 0.816**2 * RBF(length_scale=[0.109, 0.431, 0.591, 2.24])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 2/2 [00:47<00:00, 23.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 2: Fitted Kernel: 0.842**2 * RBF(length_scale=[0.187, 0.147, 1.07, 3.01])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_splits = 2  \n",
    "\n",
    "gpr_list = []\n",
    "\n",
    "# Lists to store multiple iterations of splits\n",
    "X_train_matrices, X_test_matrices = [], []\n",
    "D_train_matrices, D_test_matrices = [], []\n",
    "E_train_matrices, E_test_matrices = [], []\n",
    "train_index_matrices, test_index_matrices = [], []\n",
    "\n",
    "for split in tqdm(range(n_splits), desc=\"Training Progress\"):\n",
    "    # Perform train-test split for each dataset\n",
    "    X1_train, X1_test, D1_train, D1_test, E1_train, E1_test, train1_index, test1_index = train_test_split(\n",
    "        X1, dm1, em1, range(len(X1)), test_size=0.2, random_state=42 + split, shuffle=True)\n",
    "    X2_train, X2_test, D2_train, D2_test, E2_train, E2_test, train2_index, test2_index = train_test_split(\n",
    "        X2, dm2, em2, range(len(X2)), test_size=0.2, random_state=10 + split, shuffle=True)\n",
    "    X3_train, X3_test, D3_train, D3_test, E3_train, E3_test, train3_index, test3_index = train_test_split(\n",
    "        X3, dm3, em3, range(len(X3)), test_size=0.2, random_state=5 + split, shuffle=True)\n",
    "    X4_train, X4_test, D4_train, D4_test, E4_train, E4_test, train4_index, test4_index = train_test_split(\n",
    "        X4, dm4, em4, range(len(X4)), test_size=0.2, random_state=28 + split, shuffle=True)\n",
    "\n",
    "    # Combine all training data\n",
    "    X_train = np.concatenate((X1_train, X2_train, X3_train, X4_train))\n",
    "    D_train = np.concatenate((D1_train, D2_train, D3_train, D4_train))\n",
    "    \n",
    "    # Define the Gaussian Process kernel\n",
    "    bounds_l = ((.08, 10), (1e-2, 10.0), (1e-2, 10.0), (1e-2, 10.0))  \n",
    "    guess_l = (1,1,1,1)\n",
    "    guess_signal_var = 1.0\n",
    "    bounds_signal_var = (1e-20, 1e20)\n",
    "\n",
    "    kernel = C(constant_value=guess_signal_var, constant_value_bounds=bounds_signal_var) * \\\n",
    "             RBF(length_scale=guess_l, length_scale_bounds=bounds_l)\n",
    "    \n",
    "    # Train Gaussian Process Regressor\n",
    "    gpr = GaussianProcessRegressor(kernel=kernel, alpha=E_train**2, normalize_y=True, n_restarts_optimizer=20)\n",
    "    gpr.fit(X_train, D_train)\n",
    "    gpr_list.append(gpr)\n",
    "\n",
    "    # Append current split's train-test matrices for all datasets\n",
    "    X_train_matrices.append(np.array([X1_train, X2_train, X3_train, X4_train]))\n",
    "    X_test_matrices.append(np.array([X1_test, X2_test, X3_test, X4_test]))\n",
    "\n",
    "    D_train_matrices.append(np.array([D1_train, D2_train, D3_train, D4_train]))\n",
    "    D_test_matrices.append(np.array([D1_test, D2_test, D3_test, D4_test]))\n",
    "\n",
    "    E_train_matrices.append(np.array([E1_train, E2_train, E3_train, E4_train]))\n",
    "    E_test_matrices.append(np.array([E1_test, E2_test, E3_test, E4_test]))\n",
    "\n",
    "    train_index_matrices.append(np.array([train1_index, train2_index, train3_index, train4_index]))\n",
    "    test_index_matrices.append(np.array([test1_index, test2_index, test3_index, test4_index]))\n",
    "\n",
    "    print(f\"Split {split+1}: Fitted Kernel: {gpr.kernel_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "53176c6a-6aa8-4a2e-84c1-105cabf4ab41",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpr1 = gpr_list[0]\n",
    "gpr2 = gpr_list[1]\n",
    "Dfit1, Dstd1 = gpr1.predict(X1, return_std=True)\n",
    "Dfit2, Dstd2 = gpr1.predict(X2, return_std=True)\n",
    "Dfit3, Dstd3 = gpr1.predict(X3, return_std=True)\n",
    "Dfit4, Dstd4 = gpr1.predict(X4, return_std=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "5917b795-650a-46d8-b10b-e31fac03ec23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[142,   6,  97,  60, 112, 181, 197, 184,   9, 104, 200, 216, 236,\n",
       "        240,  67, 224, 194,  15, 177,  24, 247,  19, 114,  68, 176,  45,\n",
       "         55,  10,  30, 120, 201,  33, 141, 219,  25, 111,  18, 196, 180,\n",
       "        159, 118,  96, 108, 185, 222,  16, 146,  69, 173,  38],\n",
       "       [ 56, 127,  60, 152, 106, 119, 194,  91, 216,  49, 163, 183, 240,\n",
       "        212,  26, 224,  63, 147, 209,  87,  58, 238, 138, 144, 130,  55,\n",
       "         10,  35, 232, 103, 136, 204,  80, 235, 186,   6, 166,  24,  76,\n",
       "        105,  19, 114,  59, 124, 211,   1, 176, 187, 161,  61],\n",
       "       [215, 173, 115, 185,  50,  81, 103, 108, 223,  74,  48,  56, 225,\n",
       "        161, 130,  39, 191, 160, 150, 196, 141,  90,  82, 126, 167,  24,\n",
       "         40, 151,  47, 187, 112, 197,  33,   0, 189,  41, 247, 123, 143,\n",
       "        118, 202,   3, 163,   6, 200, 239,  88, 217,  25,  12],\n",
       "       [142, 223, 191,  20, 132, 204, 217,  95, 161,  60, 117, 148, 202,\n",
       "        172, 230, 207, 174,   1, 175, 197, 155, 229, 240,  92, 152, 134,\n",
       "         13, 156,  65,  87,  96,  31,  16, 231,  37, 185, 228,  34,  82,\n",
       "         64, 195, 136, 242, 135,  40,  91, 158, 151, 186, 165]])"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1 = test_index_matrices[0]\n",
    "test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "a85f3706-dc57-4b8d-ad89-23a8f05914a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 0 Mass set 0 Results: Mean=0.03341,Standard Deviation=0.03539,Maximum Value=0.17548\n",
      "Split 0 Mass set 1 Results: Mean=0.02594,Standard Deviation=0.03100,Maximum Value=0.14816\n",
      "Split 0 Mass set 2 Results: Mean=0.03422,Standard Deviation=0.03173,Maximum Value=0.14647\n",
      "Split 0 Mass set 3 Results: Mean=0.03603,Standard Deviation=0.03254,Maximum Value=0.12787\n",
      "Split 1 Mass set 0 Results: Mean=0.03534,Standard Deviation=0.02525,Maximum Value=0.10758\n",
      "Split 1 Mass set 1 Results: Mean=0.04056,Standard Deviation=0.06824,Maximum Value=0.47853\n",
      "Split 1 Mass set 2 Results: Mean=0.03325,Standard Deviation=0.06771,Maximum Value=0.49139\n",
      "Split 1 Mass set 3 Results: Mean=0.03603,Standard Deviation=0.05916,Maximum Value=0.42789\n"
     ]
    }
   ],
   "source": [
    "relative_difference_list = []\n",
    "for j in range(n_splits):\n",
    "    for i in range(4):\n",
    "        Xtest =  X_test_matrices[j][i]\n",
    "        x_coords = Xtest[:,0]\n",
    "        y_coords = Xtest[:,1]\n",
    "        testindices = test_index_matrices[j][i]\n",
    "        Dtrue = D_test_matrices[j][i]\n",
    "        gpr = gpr_list[j]\n",
    "        Dpred = gpr.predict(Xtest)\n",
    "        relative_difference = np.abs(Dtrue - Dpred) / np.abs(Dtrue)\n",
    "        relative_difference_list.append(relative_difference)\n",
    "        data = relative_difference\n",
    "        mean_value = np.mean(data)\n",
    "        std_value = np.std(data)\n",
    "        max_value = np.max(data) \n",
    "        print(f\"Split {j} Mass set {i} Results: Mean={mean_value:.5f},Standard Deviation={std_value:.5f},Maximum Value={max_value:.5f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
